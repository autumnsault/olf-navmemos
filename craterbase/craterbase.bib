@article{Christian2009,
author = {Christian, John A. and Lightsey, E. Glenn},
doi = {10.2514/1.42819},
file = {:Users/juno/Library/Application Support/Mendeley Desktop/Downloaded/Christian, Lightsey - 2009 - Review of options for autonomous cislunar navigation.pdf:pdf},
issn = {00224650},
journal = {Journal of Spacecraft and Rockets},
mendeley-groups = {Space/Cis-lunar navigation},
number = {5},
pages = {1023--1036},
title = {{Review of options for autonomous cislunar navigation}},
volume = {46},
year = {2009}
}
@inproceedings{Hoag1976,
  title={{The history of Apollo on-board guidance, navigation, and control}},
  author={Hoag, David G.},
  proceedings={The Eagle Has Returned; Proceedings of the Dedication Conference of the International Space Hall of Fame},
  pages={270--300},
  year={1976},
  venue={Alamogordo, New Mexico},
  publisher={American Astronautical Society; Univelt},
  address={San Diego, California}
}
@article{Hikes2017,
abstract = {Images of the Earth and Moon may be used to autonomously navigate a spacecraft in cislunar space. New optical navigation (OPNAV) techniques have revitalized interest in horizon-based methods. While the generation of precise OPNAV measurements is well understood, the measurement covariance can be rather cumbersome to compute in practice. This problem is addressed by developing a simple parametric covariance model that fully captures the geometry of measuring the lit horizon of an ellipsoidal. These simple models provide insight into the nature of the horizon-based OPNAV covariance that was previously obscured by long and difficult to understand equations.},
author = {Hikes, Jacob and Liounis, Andrew J. and Christian, John A.},
doi = {10.2514/1.G000708},
file = {:Users/juno/Library/Application Support/Mendeley Desktop/Downloaded/Hikes, Liounis, Christian - 2016 - Parametric covariance model for horizon-based optical navigation.pdf:pdf},
isbn = {9780877036333},
issn = {00653438},
journal = {Advances in the Astronautical Sciences},
mendeley-groups = {Space/Filters/Sensors/Optical/Horizon},
number = {1},
pages = {4629--4640},
title = {{Parametric covariance model for horizon-based optical navigation}},
volume = {158},
year = {2017}
}
@article{Christian2016,
author = {Christian, John A. and Robinson, Shane B.},
doi = {10.2514/1.G000539},
file = {:Users/juno/Library/Application Support/Mendeley Desktop/Downloaded/Christian, Robinson - 2016 - Noniterative horizon-based optical navigation by Cholesky factorization.pdf:pdf},
issn = {07315090},
journal = {Journal of Guidance, Control, and Dynamics},
mendeley-groups = {Space/Filters/Sensors/Optical/Horizon},
number = {12},
pages = {2755--2763},
title = {{Noniterative horizon-based optical navigation by Cholesky factorization}},
volume = {39},
year = {2016}
}
@inproceedings{Psiaki2007,
abstract = {A method has been developed for performing autonomous Lunar orbit determination based on measurements of the times at which stars set behind or rise above the Lunar limb. This system is being developed as a possible technology for use in the Lunar exploration initiative because it enables increased autonomy of operations near the Moon. The system consists of a specially modified star camera and an extended Kalman filter. The star camera keeps track of known stars in its field of view and reports the times when stars suddenly appear or disappear without crossing the edge of the field of view. These are times that the known line-of-sight vectors to the stars cross the Lunar limb, and this knowledge translates into position information. The Kalman filter uses a series of star occultation/rising times and an orbital dynamics model to estimate the spacecraft's position and velocity. An observability analysis shows that this system is strongly observable, and a truth-model simulation has demonstrated an absolute position accuracy of 70 m per axis and an absolute velocity accuracy of 0.045 m/s per axis when using a Lunar topographic map with an RMS altitude accuracy of 100 m and a Lunar gravity model with an RMS accuracy of 1x10 -5 m/s 2 .},
address = {Hilton Head, South Carolina},
author = {Psiaki, Mark L. and Hinks, Joanna C.},
booktitle = {AIAA Guidance, Navigation and Control Conference and Exhibit},
file = {:Users/juno/Downloads/10.1.1.726.1300.pdf:pdf},
mendeley-groups = {Space/Filters/Sensors/Star Occultation},
month = {aug},
number = {August},
pages = {1--14},
title = {{Autonomous lunar orbit determination using star occultation measurements}},
year = {2007}
}
@inproceedings{Landgraf2006,
abstract = {The navigation on a lunar transfer trajectory is nominally achieved by measuring the range and Doppler-shift of the telemetry link between the spacecraft and the ground-station. For this reason the existence of the link is mission critical and robotic missions fail when the telemetry link is permanently lost, for example when the on-board transceiver fails. For human missions, however, there is the possibility to make use of the crew's capability of determining the orbit by observing the apparent positions of the Moon and the Earth in front of the star background. Here a method of manual orbit determination for human lunar exploration missions is presented. Optical navigation using measurements with a sextant between landmarks and background stars has been tested by the Gemini, and used by the Apollo Astronauts. In the Apollo missions, the use of optical navigation was also used to determine the attitude of the spacecraft prior to critical manoeuvres. Here we present a more simple method that can easily be performed in an operational environment and in a even more simplified version without the use of a computer: measuring the time of occultation (eclipse) of stars by the Moon or the Earth. From these measurements the crew can determine the amount of dispersion of their spacecraft's state vector from the nominal state either by using simple navigation algorithms on laptop computers or lists of epochs tabulated before the mission. The analytical sensitivity analysis shows that for example the periselenium altitude can be determined with this method to better than 1 km with a measurement 24h before the periselenium arrival if the accuracy of the measured time of occultation is equal or better than 10 s. Examples for the application of this navigation approach are presented for lunar transfer trajectories. It is proposed to demonstrate the feasibility of the method in an experiment on board the space station.},
author = {Landgraf, Markus and Thiele, G. and Koschny, D. and Udrea, B.},
booktitle = {AIAA 57th International Astronautical Congress, IAC 2006},
doi = {10.2514/6.iac-06-c1.7.05},
file = {:Users/juno/Downloads/astronav{\_}4Sep06.pdf:pdf},
isbn = {9781605600390},
mendeley-groups = {Space/Filters/Sensors/Star Occultation},
number = {September},
pages = {4595--4600},
title = {{Optical navigation for lunar exploration missions}},
volume = {7},
year = {2006}
}
@phdthesis{Keenan1962,
author = {Keenan, Roy V. and Regenhardt, John D.},
file = {:Users/juno/Downloads/33216330-MIT.pdf:pdf},
mendeley-groups = {Space/Filters/Sensors/Star Occultation},
school = {Massachusetts Institute of Technology},
title = {{Star Occultation Measurements as an Aid to Navigation in Cis-lunar Space}},
type = {M.S. Thesis},
year = {1962}
}
@article{Christensen2011,
abstract = {As NASA prepares to return humans to the Moon and establish a long-term presence on the surface, technologies must be developed to access previously unvisited terrain regardless of the condition. Among these technologies is a guidance, navigation, and control (GN{\&}C) system capable of safely and precisely delivering a spacecraft, whether manned or robotic, to a predetermined landing area. This article presents a detailed study of both terrain-relative navigation using a terrain-scanning instrument and radiometric navigation using beacons in lunar orbit or on the surface of the Moon. The models for these sensors are developed along with a baseline sensor suite that includes an IMU, star-camera, altimeter, and velocimeter. Linear covariance analysis is used to rapidly perform the trade studies relevant to this problem and to provide the navigation performance data necessary to determine how each navigation method can be used to support a 100 m 3-$\sigma$ navigation requirement on landing.},
author = {Christensen, D. and Geller, D.},
doi = {10.1007/BF03321162},
file = {:Users/juno/Downloads/Christensen-Geller2011{\_}Article{\_}Terrain-RelativeAndBeacon-Rela.pdf:pdf},
issn = {00219142},
journal = {Journal of the Astronautical Sciences},
mendeley-groups = {Space/Filters/Sensors/Optical/Terrain},
number = {1},
pages = {121--151},
title = {{Terrain-relative and beacon-relative navigation for lunar powered descent and landing}},
volume = {58},
year = {2011}
}
@article{Robbins2019,
abstract = {This paper presents a new, global database of lunar impact craters, estimated to be a complete census of all craters with diameters larger than 1–2 km. The database contains over 2 million craters, making it larger in number than any previously published lunar effort by more than a factor of 10. Of those craters, 1.3 million have diameters ≥1 km, approximately 83,000 are ≥5 km, and 6,972 craters are ≥20 km. How the database was constructed along with the reliability of features is described in detail. Comparisons are made with past published databases, demonstrating good agreement for crater size and location. An ellipticity analysis is conducted, illustrating there is no dominant direction for elliptical crater orientation based on location, diameter range, or ellipticity amount, consistent with randomness for craters ≥10 km. A spatial density analysis is described, comparing the spatial density of small versus large craters, and numerous observations about the nonuniformity of the size distributions of craters across the Moon are made. The spatial density is also used in a discussion about kilometer-scale secondary impact craters and clearly shows that they dominate the crater population in some areas of the lunar surface. This paper presents just a tiny sample of the scientific investigations that could be done with this new crater database.},
author = {Robbins, Stuart J.},
doi = {10.1029/2018JE005592},
file = {:Users/juno/Documents/Mendeley Desktop/Robbins/2019/A new global database of lunar impact craters 1–2 km 1. Crater locations and sizes, comparisons with published databases, and global a.pdf:pdf},
issn = {21699100},
journal = {Journal of Geophysical Research: Planets},
keywords = {Moon,crater ellipticity,craters,database comparison,secondary craters},
mendeley-groups = {Space/Lunar Feature Databases},
number = {4},
pages = {871--892},
title = {{A new global database of lunar impact craters {\textgreater}1–2 km: 1. Crater locations and sizes, comparisons with published databases, and global analysis}},
volume = {124},
year = {2019}
}
@article{Maass2020,
abstract = {Interest in autonomous planetary precision landing missions has been increasing in the scientific and engineering community, and is likely to continue to do so for the foreseeable future. As an enabling technology in the context of lunar landing, DLR, German Aerospace Center has been developing a terrain absolute navigation system that matches craters detected in image data to globally available lunar crater maps. The proposed Crater Navigation (CNav) system is adaptive, comprising three different crater matching methods that are specifically tailored to different navigation conditions encountered during the vehicle descent, so that it may be used as a stand-alone navigation sensor that can be closely integrated with a lander guidance, navigation, and control system to enable reliable absolute navigation throughout the entire descent phase of a mission. As robustness is a vital aspect to mission success, the CNav system includes verification mechanisms that ensure high dependability of the resulting navigation solution. This robustness is verified separately for all of the three different matching techniques presented in this paper. Closed-loop performance of the matchers is demonstrated as well, both for simulated image data sets, as for navigation camera images acquired during the Chinese Chang'e-3 landing mission. Successful uninterrupted estimation of the entire Chang'e-3 kinematic vehicle state during the powered descent until a final altitude of 350 m above ground, with neither known camera calibration nor inertial measurement unit data available, showcases the potential of the CNav system.},
author = {Maass, Bolko and Woicke, Svenja and Oliveira, Willem M. and Razgus, Bronislovas and Kr{\"{u}}ger, Hans},
doi = {10.2514/1.G004850},
file = {:Users/juno/Library/Application Support/Mendeley Desktop/Downloaded/Maass et al. - 2020 - Crater navigation system for autonomous precision landing on the Moon.pdf:pdf},
issn = {15333884},
journal = {Journal of Guidance, Control, and Dynamics},
mendeley-groups = {Space/Image Processing/Crater Extraction,Space/Filters/Sensors/Optical/Terrain},
number = {8},
pages = {1414--1431},
title = {{Crater navigation system for autonomous precision landing on the Moon}},
volume = {43},
year = {2020}
}
@article{Christian2020,
abstract = {It is often necessary to identify a pattern of observed craters in a single image of the lunar surface and without any prior knowledge of the camera's location. This so-called "lost-in-space" crater identification problem is common in both crater-based terrain relative navigation (TRN) and in automatic registration of scientific imagery. Past work on crater identification has largely been based on heuristic schemes, with poor performance outside of a narrowly defined operating regime (e.g., nadir pointing images, small search areas). This work provides the first mathematically rigorous treatment of the general crater identification problem. It is shown when it is (and when it is not) possible to recognize a pattern of elliptical crater rims in an image formed by perspective projection. For the cases when it is possible to recognize a pattern, descriptors are developed using invariant theory that provably capture all of the viewpoint invariant information. These descriptors may be pre-computed for known crater patterns and placed in a searchable index for fast recognition. New techniques are also developed for computing pose from crater rim observations and for evaluating crater rim correspondences. These techniques are demonstrated on both synthetic and real images.},
archivePrefix = {arXiv},
arxivId = {2009.01228},
author = {Christian, John A. and Derksen, Harm and Watkins, Ryan},
eprint = {2009.01228},
file = {:Users/juno/Library/Application Support/Mendeley Desktop/Downloaded/Christian, Derksen, Watkins - 2020 - Lunar crater identification in digital images.pdf:pdf},
journal = {arXiv},
mendeley-groups = {Space/Filters/Sensors/Optical/Terrain,Mathematics/Invariants},
title = {{Lunar crater identification in digital images}},
year = {2020}
}
@article{Salamuniccar2008,
abstract = {Crater Detection Algorithms (CDAs) applications range from estimation of lunar/planetary surface age to autonomous landing on planets and asteroids and advanced statistical analyses. A large amount of work on CDAs has already been published. However, problems arise when evaluation results of some new CDA have to be compared with already published evaluation results. The problem is that different authors use different test-fields, different Ground-Truth (GT) catalogues, and even different methodologies for evaluation of their CDAs. Re-implementation of already published CDAs or its evaluation environment is a time-consuming and unpractical solution to this problem. In addition, implementation details are often insufficiently described in publications. As a result, there is a need in research community to develop a framework for objective evaluation of CDAs. A scientific question is how CDAs should be evaluated so that the results are easily and reliably comparable. In attempt to solve this issue we first analyzed previously published work on CDAs. In this paper, we propose a framework for solution of the problem of objective CDA evaluation. The framework includes: (1) a definition of the measure for differences between craters; (2) test-field topography based on the 1/64° MOLA data; (3) the GT catalogue wherein each of 17,582 craters is aligned with MOLA data and confirmed with catalogues by N.G. Barlow et al. and J.F. Rodionova et al.; (4) selection of methodology for training and testing; and (5) a Free-response Receiver Operating Characteristics (F-ROC) curves as a way to measure CDA performance. The handling of possible improvements of the framework in the future is additionally addressed as a part of discussion of results. Possible extensions with additional test-field subsystems based on visual images, data sets for other planets, evaluation methodologies for CDAs developed for different purposes than cataloguing of craters, are proposed as well. The goal of the proposed framework is to contribute to the research community by establishing guidelines for objective evaluation of CDAs. {\textcopyright} 2007 COSPAR.},
author = {Salamuni{\'{c}}car, G. and Lon{\v{c}}ari{\'{c}}, S.},
doi = {10.1016/j.asr.2007.04.028},
file = {:Users/juno/Downloads/10.1016@j.asr.2007.04.028.pdf:pdf},
issn = {02731177},
journal = {Advances in Space Research},
keywords = {Crater detection algorithms,Evaluation,Mars},
mendeley-groups = {Space/Image Processing/Crater Extraction},
number = {1},
pages = {6--19},
title = {{Open framework for objective evaluation of crater detection algorithms with first test-field subsystem based on \textsc{mola} data}},
volume = {42},
year = {2008}
}
@article{Christian2017,
abstract = {The use of images for spacecraft navigation is well established. Although these images have traditionally been processed by a human analyst on Earth, a variety of recent advancements have led to an increased interest in autonomous imaged-based spacecraft navigation. This work presents a comprehensive treatment of the techniques required to navigate using the lit limb of an ellipsoidal body (usually a planet or moon) in an image. New observations are made regarding the effect of surface albedo and terrain on navigation performance. Furthermore, study of this problem led to a new subpixel edge localization algorithm using Zernike moments, which is found to outperform existing methods for accurately finding the horizon's location in an image. The new limb localization technique is discussed in detail, along with extensive comparisons with alternative approaches. Theoretical results are validated through a variety of numerical examples.},
author = {Christian, John A.},
doi = {10.2514/1.A33692},
file = {:Users/juno/Library/Application Support/Mendeley Desktop/Downloaded/Christian - 2017 - Accurate planetary limb localization for image-based spacecraft navigation.pdf:pdf},
issn = {0022-4650},
journal = {Journal of Spacecraft and Rockets},
mendeley-groups = {Space/Filters/Sensors/Optical,Space/Filters/Sensors/Optical/Horizon},
pages = {1--23},
title = {{Accurate planetary limb localization for image-based spacecraft navigation}},
url = {https://arc.aiaa.org/doi/10.2514/1.A33692},
year = {2017}
}
@article{Woicke2018,
abstract = {Precise landings on other bodies require more than just dead reckoning using an inertial measurement unit on-board the lander. If navigation of the lander with respect to a planetary surface is desired, so-called crater detection and crater-matching algorithms might be a valuable asset to find the inertial position of the vehicle using terrain relative navigation techniques. This would enable landing close to an inertially defined landing site, which could, for example, be a surface asset of a previous mission. With the desire to reduce the landing ellipse size, more precise knowledge of the inertial state of the lander is required. Based on an extensive literature review, six different algorithms were implemented to assess the performance of these. This assessment will aid the selection of crater-detection techniques for future precision landing missions. To compare the different algorithms trade-off criteria have been established. The following criteria are assessed: 1) True detection rates 2) False detection rates 3) Accuracy: as the reference maps usually have rather high resolution, inaccuracies of just a few pixels can cause large errors. 4) Run-time: the algorithm should be on-board capable. Moreover, the robustness of the algorithms was investigated. It was found that all algorithms are capable of performing the task of extracting sufficient craters for localising the landing vehicle with respect to a surface map. A method based on extracting and clustering lit pixels delivered the most promising results for the overall detections, whereas, the machine-learning based algorithms showed slightly better robustness.},
author = {Woicke, Svenja and {Moreno Gonzalez}, Andres S. and El-Hajj, Isabelle and Mes, Jelle W.F. and Henkel, Martin and Autar, R. S.D. and Klavers, Robert A.},
doi = {10.2514/6.2018-1601},
file = {:Users/juno/Documents/Mendeley Desktop/Woicke et al/2018/Comparison of crater-detection algorithms for terrain-relative navigation.pdf:pdf},
isbn = {9781624105265},
journal = {AIAA Guidance, Navigation, and Control Conference, 2018},
mendeley-groups = {Space/Image Processing/Ellipse Extraction,Space/Image Processing/Crater Extraction},
number = {210039},
pages = {1--12},
title = {{Comparison of crater-detection algorithms for terrain-relative navigation}},
year = {2018}
}
@article{Maass2016,
abstract = {This paper describes an efficient and easily implemented algorithmic approach to extracting an approximation to an image's dominant projected illumination direction, based on intermediary results from a segmentation-based crater detection algorithm (CDA), at a computational cost that is negligible in comparison to that of the prior stages of the CDA. Most contemporary CDAs built for spacecraft navigation use this illumination direction as a means of improving performance or even require it to function at all. Deducing the illumination vector from the image alone reduces the reliance on external information such as the accurate knowledge of the spacecraft inertial state, accurate time base and solar system ephemerides. Therefore, a method such as the one described in this paper is a prerequisite for true “Lost in Space” operation of a purely segmentation-based crater detecting and matching method for spacecraft navigation. The proposed method is verified using ray-traced lunar elevation model data, asteroid image data, and in a laboratory setting with a camera in the loop.},
author = {Maass, Bolko},
doi = {10.1007/s12567-016-0129-1},
file = {:Users/juno/Downloads/art{\_}10.1007{\_}s12567-016-0129-1 Maass.pdf:pdf},
issn = {18682510},
journal = {CEAS Space Journal},
keywords = {Crater detection,Illumination estimation,Spacecraft navigation},
mendeley-groups = {Space/Image Processing/Crater Extraction},
number = {4},
pages = {303--314},
title = {{Robust approximation of image illumination direction in a segmentation-based crater detection algorithm for spacecraft navigation}},
volume = {8},
year = {2016}
}
@inproceedings{Stewart2020,
address = {Breckenridge, Colorado},
author = {Stewart, S. and Crain, T. and Molina-Ramos, G.},
booktitle = {Proceedings of the AAS Guidance, Navigation and Control Conference},
mendeley-groups = {Space/Filters/Sensors/Optical},
month = {jan},
title = {{Thin\textsc{vpu}: Open source vision processing for space navigation}},
year = {2020}
}
@article{DeLatte2019,
abstract = {Convolutional Neural Networks (CNN) offer promising opportunities to automatically glean scientifically relevant information directly from annotated images, without needing to handcraft features for detection. Crater counting started with hand counting hundreds, thousands, or even millions of craters in order to determine the age of geological units on planetary bodies of the solar system. Automated crater detection algorithms have attempted to speed up this process. Previous research has employed computer vision techniques with handcrafted features such as light and shadow patterns, circle finding, or edge detection. This research continues, but now some researchers use techniques like convolutional neural networks that enable the algorithm to develop its own features. As the field of machine learning undergoes exponential growth in terms of paper count and research methods, the crater counting application can benefit from the new research, especially when conducting joint interdisciplinary projects. Despite these advancements, the crater counting community has not yet adopted standard methods for automating the process despite decades of research. This survey enumerates challenges for both planetary geologists and machine learning researchers, looks at the recent automatic crater detection advancements using machine learning techniques (primarily in methods using CNNs), and makes recommendations for the path toward greater automation.},
author = {DeLatte, D. M. and Crites, S. T. and Guttenberg, N. and Yairi, T.},
doi = {10.1016/j.asr.2019.07.017},
file = {:Users/juno/Downloads/delatte2019.pdf:pdf},
issn = {18791948},
journal = {Advances in Space Research},
keywords = {Automation,Convolutional neural networks,Crater detection,Feature extraction,Machine learning,Mars},
mendeley-groups = {Space/Image Processing/Crater Extraction},
number = {8},
pages = {1615--1628},
publisher = {COSPAR},
title = {{Automated crater detection algorithms from a machine learning perspective in the convolutional neural network era}},
volume = {64},
year = {2019}
}
@article{Bandeira2007,
abstract = {This paper presents a methodology that brings together a number of techniques in the fields of image processing and pattern recognition with the purpose of achieving the automated detection of impact craters on images of planetary surfaces. The modular approach adopted for its development includes a phase of candidate selection, followed by template matching, in which the probability associated to each detection is established, and finally, by the analysis of the probability volume, in which the identification of craters on the image is achieved. It is tested on a set of images from four different regions of the surface of the planet Mars, all obtained by the same sensor in the last decade. The recognition rates for craters with radii that are larger than five pixels are very good, both globally and for each of the individual areas. The performance of the algorithm in the face of the variation of some of its parameters is analyzed and discussed in detail. We believe that this is a tool that is suitable for a general application in any area of a planet or satellite captured in an image, whatever the geomorphological setting, the optical sensor, and the conditions of illumination are. {\textcopyright} 2007 IEEE.},
author = {Bandeira, Louren{\c{c}}o and Saraiva, Jos{\'{e}} and Pina, Pedro},
doi = {10.1109/TGRS.2007.904948},
file = {:Users/juno/Downloads/TGRS2007{\_}preprint.pdf:pdf},
issn = {01962892},
journal = {IEEE Transactions on Geoscience and Remote Sensing},
keywords = {Circular feature recognition,Impact craters,Mars,Template matching},
mendeley-groups = {Space/Image Processing/Crater Extraction},
number = {12},
pages = {4008--4015},
title = {{Impact crater recognition on mars based on a probability volume created by template matching}},
volume = {45},
year = {2007}
}
@article{Troglio2012,
abstract = {With the launch of several planetary missions in the last decade, a large amount of planetary images has been already acquired and much more will be available for analysis in the coming years. The image data need to be analyzed, preferably by automatic processing techniques because of the huge amount of data. Although many automatic feature extraction methods have been proposed and utilized for earth remote sensing images, these methods are not always applicable to planetary data that often present low contrast and uneven illumination characteristics. Here, we propose a new unsupervised method for the extraction of different features of elliptical and geometrically compact shapes, such as craters and rocks of compact shape (e.g., boulders), to be used for image registration purposes. This approach is based on the combination of several image processing techniques, including watershed segmentation and the generalized Hough transform. The method potentially has application for extraction of craters, rocks, and other geological features. {\textcopyright} 2011 IEEE.},
author = {Troglio, Giulia and {Le Moigne}, Jacqueline and Benediktsson, Jn Atli and Moser, Gabriele and Serpico, Sebastiano B.},
doi = {10.1109/LGRS.2011.2161263},
file = {:Users/juno/Downloads/troglio2012.pdf:pdf},
issn = {1545598X},
journal = {IEEE Geoscience and Remote Sensing Letters},
keywords = {Crater detection,Hough transform,feature extraction,watershed segmentation},
mendeley-groups = {Space/Image Processing/Ellipse Extraction,Space/Image Processing/Crater Extraction},
number = {1},
pages = {95--99},
title = {{Automatic extraction of ellipsoidal features for planetary image registration}},
volume = {9},
year = {2012}
}
@article{Barker2016,
author = {Barker, M.K. and Mazarico, E. and Neumann, G.A. and Zuber, M.T. and Haruyama, J. and Smith, D.E.},
doi = {10.1016/j.icarus.2015.07.039},
file = {:Users/juno/Library/Application Support/Mendeley Desktop/Downloaded/Barker et al. - 2016 - A new lunar digital elevation model from the Lunar Orbiter Laser Altimeter and SELENE Terrain Camera.pdf:pdf},
issn = {00191035},
journal = {Icarus},
mendeley-groups = {Space/Lunar DEM,Space/Landing site selection,Space},
month = {jul},
pages = {346--355},
publisher = {Elsevier Inc.},
title = {{A new lunar digital elevation model from the Lunar Orbiter Laser Altimeter and \textsc{selene} Terrain Camera}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0019103515003450},
volume = {273},
year = {2016}
}
@article{Gupta1997,
abstract = {Modelling and analyzing pushbroom sensors commonly used in satellite imagery is difficult and computationally intensive due to the motion of the orbiting satellite with respect to the rotating earth, and the non-linearity of the mathematical model involving orbital dynamics. The linear pushbroom model) introduced in this paper has the advantage of computational simplicity while at the same time giving very accurate results compared with the full orbiting pushbroom model. The common photogrammetric problems may be solved easily for the linear pushbroom model. The linear pushbroom model leads to theoretical insights that are approximately valid for the full model as well. The epipolar geometry of a linear pushbroom camera is different from that of a perspective camera. Nevertheless, a matrix analogous to the fundamental matrix of perspective cameras is shown to exist for linear pushbroom sensors. From this it is shown that a scene is determined up to an affine transformation from two views with linear pushbroom cameras.},
author = {Gupta, Rajiv and Hartley, R.I.},
doi = {10.1109/34.615446},
file = {:Users/juno/Documents/Mendeley Desktop/Gupta, Hartley/1997/Linear pushbroom cameras.pdf:pdf},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {fundamental matrix,photogrammetry,pushbroom sensor,satellite cameras},
mendeley-groups = {Space/Image Processing/Camera Projections},
number = {9},
pages = {963--975},
title = {{Linear pushbroom cameras}},
url = {http://ieeexplore.ieee.org/document/615446/},
volume = {19},
year = {1997}
}
@article{Woodham1980,
abstract = {A novel technique called photometric stereo is introduced. The idea is to vary the direction of incident illumination between successive images, while holding the viewing direction constant. This provides sufficient information to determine surface orientation at each point. Since the imaging geometry is not changed, the correspondence between image points is known a priori. The technique uses the radiance values recorded at a single image location, in successive views, rather than the relative positions of displaced features. Photometric stereo is used in computer-based image understanding. It can be applied in two ways. First, it is a general technique for determining surface orientation at each image point. Second, it is a technique for determining object points that have a particular surface orientation},
author = {Woodham, Robert J.},
doi = {10.1117/12.7972479},
file = {:Users/john/Documents/Mendeley Desktop/Woodham/Unknown/Photometric method for determining surface orientation from multiple images.pdf:pdf},
issn = {0091-3286},
journal = {Optical Engineering},
mendeley-groups = {Photoclinometry},
number = {1},
title = {{Photometric method for determining surface orientation from multiple images}},
volume = {19},
year = {1980},
pages = {139-144}
}
@article{Liu2020,
abstract = {High-resolution 3D information on lunar and planetary surfaces is crucial for planetary exploration missions and science. Photogrammetry is a state-of-the-art technology for generating 3D topographic models of surfaces such as digital elevation models (DEMs). The performance of the photogrammetry and the resulting DEMs is affected by image matching. However, most matching algorithms fail when the images have large differences in illumination and subtle textures. This problem can be addressed by integrating photoclinometry into the photogrammetric process. This paper presents an integrated photogrammetric and photoclinometric approach that is able to generate pixel-resolution DEMs of the lunar surface and is illumination invariant. The incorporation of photoclinometry into photogrammetry involves two main steps. First, a photoclinometry assisted image matching (PAM) approach is developed by integrating photometric stereo analysis in the image matching to create pixel-wise matches, even for images with large illumination differences. Second, the DEM derived from photogrammetry using the matching results is further refined to pixel-wise resolution using photoclinometry with a shadow constraint. The proposed approach has been used for high-resolution topographic mapping at the Chang'E-4 and Chang'E-5 landing sites using Lunar Reconnaissance Orbiter Camera (LROC) Narrow Angle Camera (NAC) images acquired under different illumination conditions. The results indicate that the proposed approach is robust to severe inconsistencies in illumination and subtle textures in cases where the conventional approaches fail. The approach is able to achieve geometric accuracies comparable to photogrammetry but more small-scale topographic details. The proposed approach can also be used for high-resolution topographic mapping of other planetary bodies such as Mercury or asteroids, and provides a useful reference for similar topographic mapping on Earth.},
author = {Liu, Wai Chung and Wu, Bo},
doi = {10.1016/j.isprsjprs.2019.11.017},
file = {:Users/john/Documents/Mendeley Desktop/Liu, Wu/2020/ISPRS Journal of Photogrammetry and Remote Sensing An integrated photogrammetric and photoclinometric approach for illumination-invarian.pdf:pdf},
issn = {09242716},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
keywords = {Image matching,Moon,Photoclinometry,Photogrammetry,Shape-from-shading},
mendeley-groups = {Photoclinometry},
pages = {153--168},
title = {{An integrated photogrammetric and photoclinometric approach for illumination-invariant pixel-resolution \textsc{3d} mapping of the lunar surface}},
volume = {159},
year = {2020}
}
@article{Horn1977,
abstract = {Traditionally, image intensities have been processed to segment an image into regions or to find edge-fragments. Image intensities carry a great deal more information about three-dimensional shape, however. To exploit this information, it is necessary to understand how images are formed and what determines the observed intensity in the image. The gradient space, popularized by Huffman and Mackworth in a slightly different context, is a helpful tool in the development of new methods. {\textcopyright} 1977.},
author = {Horn, Berthold K. P.},
doi = {10.1016/0004-3702(77)90020-0},
file = {:Users/john/Documents/Mendeley Desktop/Horn/1977/Understanding image intensities.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Edge detection,Glossy surfaces,Gradient space,Image Understanding,Image brightness,Image formation,Lunar surface,Matte surfaces,Mutual illumination,Recovering topography,Reflectance map,Shape from shading,Specular surfaces,Surface orientation,Understanding the imaging process},
mendeley-groups = {Photoclinometry},
number = {2},
pages = {201--231},
title = {{Understanding image intensities}},
volume = {8},
year = {1977}
}
@phdthesis{Kirk1987,
author = {Kirk, R. L.},
school = {California Institute of Technology},
title = {{A Fast Finite-Element Algorithm for Two-Dimensional Photoclinometry}},
type = {Dissertation},
year = {1987}
}
@article{Brown2017,
abstract = {We present Tetra, a star identification algorithm that uses the minimum possible computation time and number of database accesses to solve the calibrationless lost-in-space problem. To solve the calibrationless lost-in-space problem, a star tracker must determine its attitude with no a priori knowledge, not even lens parameters such as the field-of-view or distortions. Tetra is based on a directly-addressed hash table data structure, which enables it to identify star patterns with a single database access. We prove a tight bound on Tetra's false positive rate and empirically compare Tetra's runtime, centroiding error sensitivity, and field-of-view error sensitivity with earlier lost-in-space algorithms: Pyramid and Nondimensional Star ID. We also compare Tetra with hash table based modifications of Pyramid's cross-referencing step and Nondimensional Star ID's database lookup, which improve Pyramid and Nondimensional Star ID's runtimes by an order of magnitude without otherwise impacting their performance. We find that Tetra outperforms the earlier algorithms and their improved counterparts in every measured metric: runtime, centroiding error sensitivity, and field-of-view error sensitivity. Tetra, our free software alternative (https://github.com/brownj4/Tetra), will enable the next generation of spacecraft navigation technology.},
author = {Brown, Julian and Cahoy, Kerri},
file = {:Users/juno/Library/Application Support/Mendeley Desktop/Downloaded/Brown, Cahoy - 2017 - TETRA Star identification with hash tables.pdf:pdf},
journal = {AIAA/USU Conference on Small Satellites},
mendeley-groups = {Space/Filters/Sensors/Star Tracker},
number = {831},
title = {{\textsc{Tetra}: Star identification with hash tables}},
url = {http://digitalcommons.usu.edu/cgi/viewcontent.cgi?article=3655\&context=smallsat},
year = {2017}
}
@article{Gorski2005,
abstract = {HEALPix -- the Hierarchical Equal Area iso-Latitude Pixelization -- is a versatile data structure with an associated library of computational algorithms and visualization software that supports fast scientific applications executable directly on very large volumes of astronomical data and large area surveys in the form of discretized spherical maps. Originally developed to address the data processing and analysis needs of the present generation of cosmic microwave background (CMB) experiments (e.g. BOOMERanG, WMAP), HEALPix can be expanded to meet many of the profound challenges that will arise in confrontation with the observational output of future missions and experiments, including e.g. Planck, Herschel, SAFIR, and the Beyond Einstein CMB polarization probe. In this paper we consider the requirements and constraints to be met in order to implement a sufficient framework for the efficient discretization and fast analysis/synthesis of functions defined on the sphere, and summarise how they are satisfied by HEALPix.},
archivePrefix = {arXiv},
arxivId = {astro-ph/0409513},
author = {Gorski, K. M. and Hivon, E. and Banday, A. J. and Wandelt, B. D. and Hansen, F. K. and Reinecke, M. and Bartelmann, M.},
doi = {10.1086/427976},
eprint = {0409513},
file = {:Users/john/Documents/Mendeley Desktop/Gorski et al/2005/HEALPix A framework for high-resolution discretization and fast analysis of data distributed on the sphere.pdf:pdf},
issn = {0004-637X},
journal = {The Astrophysical Journal},
mendeley-groups = {Space/Geodesy/Projections},
number = {2},
pages = {759--771},
primaryClass = {astro-ph},
title = {{\textsc{Heal}Pix: A framework for high-resolution discretization and fast analysis of data distributed on the sphere}},
volume = {622},
year = {2005}
}
